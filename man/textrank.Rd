% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/textrank.R
\name{textrank}
\alias{textrank}
\title{Textrank - extract relevant sentences and keywords}
\usage{
textrank(data, terminology, method = textrank_dist, max = 1000,
  options_pagerank = list(directed = FALSE), ...)
}
\arguments{
\item{data}{a data.frame with 1 row per sentence where the first column
is an identifier of a sentence (e.g. textrank_id) and the second column is the raw sentence. See the example.}

\item{terminology}{a data.frame with tokens which are part of the sentence. Where the first column
is the identifier which corresponds to the first column of \code{data} and the second column indicates
the token which is part of the sentence. See the example.}

\item{method}{a function which calculates the distance between 2 vectors of tokens. The first 2 arguments of the function
are the tokens in sentence1 and sentence2. The function should return a numeric value of length one. The larger the value,
the larger the connection between the 2 vectors indicating more strength. Defaults to the jaccard distance,
indicating the percent of common tokens. For a large number of sentences, you might be interested in looking at the minhash algorithm
which is part of the textreuse package.}

\item{max}{integer indicating to reduce the number of sentence to sentence combinations to compute.}

\item{options_pagerank}{a list of arguments passed on to \code{\link[igraph]{page_rank}}}

\item{...}{arguments passed on to \code{method}}
}
\value{
an object of class textrank
which is a list with elements:
\itemize{
\item sentences: a data.frame with columns textrank_id, sentence and textrank where the textrank is the Google Pagerank importance metric of the sentence
\item sentences_dist: a data.frame with columns textrank_id_1, textrank_id_2 (the sentence id) and weight which
is the result of the computed distance between the 2 sentences
\item pagerank: the result of a call to \code{\link[igraph]{page_rank}}
}
}
\description{
The textrank algorithm is a technique to rank sentences in order of importance and can also be used to
identify the most relevant keywords or key phrases in text.\cr

In order to find relevant sentences, the textrank algorithm needs 2 inputs:
a data.frame (\code{data}) with sentences and a data.frame (\code{terminology})
containing tokens which are part of each sentence.\cr
Based on these 2 datasets, it calculates the pairwise distance between each sentence by computing
how many terms are overlapping (Jaccard distance). These pairwise distances among the sentences are next passed on to
Google's pagerank algorithm to identify the most relevant sentences.\cr\cr

For extracting keywords the flow is similar, but is still under construction
}
\examples{
data(joboffer)
head(joboffer)

sentences <- unique(joboffer[, c("sentence_id", "sentence")])
cat(sentences$sentence)
terminology <- subset(joboffer, upos \%in\% c("NOUN", "ADJ"), select = c("sentence_id", "lemma"))
head(terminology)

## Textrank for finding the most relevant sentences
tr <- textrank(data = sentences, terminology = terminology)
summary(tr, n = 2)
summary(tr, n = 5, keep.sentence.order = TRUE)
}
\seealso{
\code{\link[igraph]{page_rank}}
}
